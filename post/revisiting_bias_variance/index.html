<!DOCTYPE html><html lang="en-us" >

<head>

  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="generator" content="Source Themes Academic 4.8.0">

  

  
  
  
  
  
    
    
    
  
  

  <meta name="author" content="Tom Beer">

  
  
  
    
  
  <meta name="description" content="A classical principle in modern times">

  
  <link rel="alternate" hreflang="en-us" href="https://tom-beer.github.io/post/revisiting_bias_variance/">

  


  
  
  
  <meta name="theme-color" content="#2962ff">
  

  
  
  
  <script src="/js/mathjax-config.js"></script>
  

  
  
  
  
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/academicons/1.8.6/css/academicons.min.css" integrity="sha256-uFVgMKfistnJAfoCUQigIl+JfUaP47GrRKjf6CTPVmw=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css" integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin="anonymous">

    
    
    
      
    
    
      
      
        
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin="anonymous" title="hl-light">
          <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css" crossorigin="anonymous" title="hl-dark" disabled>
        
      
    

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css" integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin="anonymous">
    

    

    
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js" integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    
      

      
      

      
    
      

      
      

      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js" integrity="" crossorigin="anonymous" async></script>
      
    
      

      
      

      
    

  

  
  
  
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap">
  

  
  
  
  
  <link rel="stylesheet" href="/css/academic.css">

  




  


  
  

  

  <link rel="manifest" href="/index.webmanifest">
  <link rel="icon" type="image/png" href="/images/icon_huce93ec8a6fd7e12c2beec32639fe78a0_7050_32x32_fill_lanczos_center_2.png">
  <link rel="apple-touch-icon" type="image/png" href="/images/icon_huce93ec8a6fd7e12c2beec32639fe78a0_7050_192x192_fill_lanczos_center_2.png">

  <link rel="canonical" href="https://tom-beer.github.io/post/revisiting_bias_variance/">

  
  
  
  
  
  
  
    
  
  
  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@aTomBeer">
  <meta property="twitter:creator" content="@aTomBeer">
  
  <meta property="og:site_name" content="Tom Beer">
  <meta property="og:url" content="https://tom-beer.github.io/post/revisiting_bias_variance/">
  <meta property="og:title" content="Revisiting the bias variance tradeoff | Tom Beer">
  <meta property="og:description" content="A classical principle in modern times"><meta property="og:image" content="https://tom-beer.github.io/post/revisiting_bias_variance/featured.png">
  <meta property="twitter:image" content="https://tom-beer.github.io/post/revisiting_bias_variance/featured.png"><meta property="og:locale" content="en-us">
  
    
      <meta property="article:published_time" content="2022-07-25T10:13:42&#43;03:00">
    
    <meta property="article:modified_time" content="2022-07-25T10:13:42&#43;03:00">
  

  


    






  




<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://tom-beer.github.io/post/revisiting_bias_variance/"
  },
  "headline": "Revisiting the bias variance tradeoff",
  
  "image": [
    "https://tom-beer.github.io/post/revisiting_bias_variance/featured.png"
  ],
  
  "datePublished": "2022-07-25T10:13:42+03:00",
  "dateModified": "2022-07-25T10:13:42+03:00",
  
  "author": {
    "@type": "Person",
    "name": "Tom Beer"
  },
  
  "publisher": {
    "@type": "Organization",
    "name": "Tom Beer",
    "logo": {
      "@type": "ImageObject",
      "url": "https://tom-beer.github.io/images/icon_huce93ec8a6fd7e12c2beec32639fe78a0_7050_192x192_fill_lanczos_center_2.png"
    }
  },
  "description": "A classical principle in modern times"
}
</script>

  

  


  


  





  <title>Revisiting the bias variance tradeoff | Tom Beer</title>

</head>

<body id="top" data-spy="scroll" data-offset="70" data-target="#TableOfContents" >

  <aside class="search-results" id="search">
  <div class="container">
    <section class="search-header">

      <div class="row no-gutters justify-content-between mb-3">
        <div class="col-6">
          <h1>Search</h1>
        </div>
        <div class="col-6 col-search-close">
          <a class="js-search" href="#"><i class="fas fa-times-circle text-muted" aria-hidden="true"></i></a>
        </div>
      </div>

      <div id="search-box">
        
        
        
      </div>

    </section>
    <section class="section-search-results">

      <div id="search-hits">
        
      </div>

    </section>
  </div>
</aside>


  







<nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id="navbar-main">
  <div class="container">

    
    <div class="d-none d-lg-inline-flex">
      <a class="navbar-brand" href="/">Tom Beer</a>
    </div>
    

    
    <button type="button" class="navbar-toggler" data-toggle="collapse"
            data-target="#navbar-content" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span><i class="fas fa-bars"></i></span>
    </button>
    

    
    <div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none">
      <a class="navbar-brand" href="/">Tom Beer</a>
    </div>
    

    
    
    <div class="navbar-collapse main-menu-item collapse justify-content-start" id="navbar-content">

      
      <ul class="navbar-nav d-md-inline-flex">
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#about"><span>Home</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#posts"><span>Posts</span></a>
        </li>

        
        

        

        
        
        
          
        

        
        
        
        
        
        
          
          
          
            
          
          
        

        <li class="nav-item">
          <a class="nav-link " href="/#publications"><span>Publications</span></a>
        </li>

        
        

      

        
      </ul>
    </div>

    <ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2">
      

      
      <li class="nav-item dropdown theme-dropdown">
        <a href="#" class="nav-link js-theme-selector" data-toggle="dropdown" aria-haspopup="true">
          <i class="fas fa-palette" aria-hidden="true"></i>
        </a>
        <div class="dropdown-menu">
          <a href="#" class="dropdown-item js-set-theme-light">
            <span>Light</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-dark">
            <span>Dark</span>
          </a>
          <a href="#" class="dropdown-item js-set-theme-auto">
            <span>Automatic</span>
          </a>
        </div>
      </li>
      

      

    </ul>

  </div>
</nav>


  <article class="article">

  












  

  
  
  
<div class="article-container pt-3">
  <h1>Revisiting the bias variance tradeoff</h1>

  
  <p class="page-subtitle">A classical principle in modern times</p>
  

  
    


<div class="article-metadata">

  
  

  
  <span class="article-date">
    
    
      
    
    Jul 25, 2022
  </span>
  

  

  
  <span class="middot-divider"></span>
  <span class="article-reading-time">
    5 min read
  </span>
  

  
  
  

  
  

</div>

    














  
</div>



  <div class="article-container">

    <div class="article-style">
      <h3 id="background">Background</h3>
<p>A while ago I was tasked with developing a model predicting whether patients would be referred to the emergency room,
based on their medical presentation, demographics, etc.
The random forest was performing much better on the train set than on the test set.
Technically, it&rsquo;s a case of overfitting, but there was a disagreement among my peers if this was a bad thing or not.
After all, it was better than models that did not exhibit a train-test gap (e.g. logistic regression).
But still I was not able to convince that test performance is all that should matter.
So I had a little literature review, and presented it in our weekly journal club.
This post is a summary of that presentation.</p>
<hr>
<h3 id="intro">Intro</h3>
<p>Every intro to ML course or textbook teaches us the bias variance tradeoff as universal truth -
that test error curve follows a U-shape with respect to model complexity.</p>
<blockquote>
<p>“This is a fundamental property of statistical learning that holds regardless of the particular data set at hand and regardless of the statistical method being used.”</p>
</blockquote>
<p>Quote and figure from 
<a href="https://hastie.su.domains/ISLR2/ISLRv2_website.pdf" target="_blank" rel="noopener">ISLRv2, 2021</a></p>
<img src="image5.png" width=600 height=600 align="middle">
<p>Yet everywhere around us we see evidence that “bigger models are always better”
<sup>
<a href="https://microsoft.com/en-us/research/blog/using-deepspeed-and-megatron-to-train-megatron-turing-nlg-530b-the-worlds-largest-and-most-powerful-generative-language-model/" target="_blank" rel="noopener">1</a>,

<a href="http://proceedings.mlr.press/v97/tan19a/tan19a.pdf" target="_blank" rel="noopener">2</a></sup></p>
<img src="image4.png" width=1400 height=1400 align="middle">
<p>How do we relieve this tension? Is it just the difference between traditional machine learning and deep learning?
Is the tradeoff real at all? Let’s take a stab at settling this.</p>
<hr>
<h3 id="the-defense">The Defense</h3>
<p>On the one hand, there is empirical grounding for the tradeoff - it can be shown to exist in models like KNN, polynomial regression, kernel regression, decision trees and more.</p>
<p>There is some theoretical justification for it too. Generalization bounds that grow with complexity (VC/Rademacher) are interpreted as if simple models are preferable.</p>
<blockquote>
<p>“In real applications, learning models with lower VC(H) tend to generalize better”, Learning From Data, 2021</p>
</blockquote>
<img src="image6.png" width=1400 height=1400 align="middle">
<img src="image8.png" width=1400 height=1400 align="middle">
<p>As an ML history fun fact, the tradeoff was not popularized until the 1992 paper
“Neural Networks and the Bias/Variance Dilemma” by Geman et. al.
This same paper also introduced the <strong>decomposition</strong> of the MSE to bias and variance components.
As the decomposition is usually discussed in the same context, it adds to the strong intuition of the tradeoff (even though it does not imply it).</p>
<hr>
<h3 id="the-cracks">The Cracks</h3>
<p>The empirical and theoretical arguments seem fair, but let&rsquo;s see if they stand up to some scrutiny.</p>
<p>As far back as 95’ there have been works showing that variance remains low for models with increasing complexity.
Curiously, inconsistencies between classical and neural models are demonstrated even in the 92' paper that popularized the tradeoff:</p>
<img src="image7.png" width=600 height=600 align="middle">
<p>but the authors dismiss them as related to the training procedure and not a fundamental property of the model class.</p>
<p>As for the generalization bounds, they are too loose to accurately reflect the test error’s trend in practice.</p>
<p>While these were not sufficient to change the community’s opinion on the tradeoff, it seems that the tide has started to shift in the last 4 years.
In 2019 
<a href="https://www.pnas.org/doi/10.1073/pnas.1903070116" target="_blank" rel="noopener">Mikhail Belkin and colleagues</a> coined <em>double descent</em> to describe a fairly prevalent phenomenon where the
standard bias-variance picture breaks down once zero training error is attained - what they call the
<em>interpolation threshold</em>. Before the interpolation threshold, the tradeoff holds and increasing model
complexity leads to overfitting. After the interpolation threshold, however, they found that test error actually starts to go down as you keep increasing model complexity.
This is shown for fully connected networks, random forest and a random fourier feature model.</p>
<img src="image9.png">
<p>Concurrent work by 
<a href="https://mltheory.org/deep.pdf" target="_blank" rel="noopener">Nakkiran et al.</a> has proved that double descent w.r.t <em>model width</em> is a robust phenomenon that occurs in a variety of tasks, architectures (CNNs, ResNets, Transformers), and optimization methods.</p>
<img src="image2.png">
<p>But more interesting is the phenomenon of training time double descent - training for more epochs decreases performance (before improving again),</p>
<img src="image3.png">
<p>And dataset size double descent - using more training samples (x4.5 more in their experiments) decreases performance before improving again.</p>
<img src="image1.png">
<p>In some experiments, a single descent (rather than double descent) was observed. But a U-shaped loss curve was never observed for neural nets! Which aligns with the modern practice of “bigger is better”.</p>
<hr>
<h3 id="reconciling-theory-and-practice">Reconciling theory and practice</h3>
<p>There are some suggestive explanations for this deflection between theory and practice.
Many revolve around the notion of complexity - that we just don’t have a proper measure of it.
One for which larger models could actually be simpler.
Regardless of whether you accept one of the hypotheses, you can’t argue with the science.
After all, theory is subordinate to science, as this

<a href="https://twitter.com/tomgoldsteincs/status/1484609273162309634?lang=en" target="_blank" rel="noopener">great talk</a>
by Tom Goldstein calls for.</p>
<p>
<a href="https://arxiv.org/abs/1912.08286" target="_blank" rel="noopener">Brady Neal’s work</a> on this very subject is subtitled “Textbooks need an update”.
And indeed recent books include double descent in their discussion of the bias variance tradeoff.
Examples include 
<a href="https://hastie.su.domains/ISLR2/ISLRv2_website.pdf" target="_blank" rel="noopener">ISLRv2</a>,

<a href="https://di.ens.fr/~fbach/ltfp_book.pdf" target="_blank" rel="noopener">LTFP</a>
and 
<a href="https://mlstory.org/pdf/patterns.pdf" target="_blank" rel="noopener">ML Story</a>.</p>
<p>Still, more effort should be put in teaching that the bias variance tradeoff is not a universal truth, at least based on the measures of complexity we use in our everyday practice. This has implications on how we select and evaluate ML models.</p>
<p>As a personal note, what’s still missing for me is a rule of thumb for determining if some case of overfitting
(train error &laquo; test error) is benign, or should it suggest that a different model should be selected.</p>
<hr>

    </div>

    



















  
  





  
    
    
    
      
    
    
    
    <div class="media author-card content-widget-hr">
      
        
        <img class="avatar mr-3 avatar-circle" src="/author/tom-beer/avatar_hu9034ec2da80e6325848318956e058d92_564834_270x270_fill_q90_lanczos_center.jpg" alt="Tom Beer">
      

      <div class="media-body">
        <h5 class="card-title"><a href="https://tom-beer.github.io/">Tom Beer</a></h5>
        
        
        <ul class="network-icon" aria-hidden="true">
  
    
    
    
      
    
    
    
    
    
    <li>
      <a href="mailto:tom.beer@khealth.ai" >
        <i class="fas fa-envelope"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://twitter.com/aTomBeer" target="_blank" rel="noopener">
        <i class="fab fa-twitter"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://www.linkedin.com/in/tom-beer/" target="_blank" rel="noopener">
        <i class="fab fa-linkedin"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://github.com/tom-beer" target="_blank" rel="noopener">
        <i class="fab fa-github"></i>
      </a>
    </li>
  
    
    
    
      
    
    
    
    
    
      
    
    <li>
      <a href="https://huggingface.co/tom-beer" target="_blank" rel="noopener">
        <i class="fab fa-face-smiling-hands"></i>
      </a>
    </li>
  
    
    
    
    
    
    
    
      
    
    <li>
      <a href="https://scholar.google.com/citations?user=6wZ70dEAAAAJ&amp;hl=en" target="_blank" rel="noopener">
        <i class="ai ai-google-scholar"></i>
      </a>
    </li>
  
</ul>

      </div>
    </div>
  
















  </div>
</article>

      

    
    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js" integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js" integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin="anonymous"></script>
      <script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin="anonymous"></script>

      

      
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin="anonymous"></script>
        
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js"></script>
        
      

    

    
    
      <script src="https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js" integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin="anonymous"></script>
    

    
    
    <script>const code_highlighting = true;</script>
    

    
    
    <script>const isSiteThemeDark = false;</script>
    

    

    
    

    

    
    

    
    

    
    

    
    

    
    
    
    
    
    
    
    
    
    
    
    
    <script src="/js/academic.min.6f7ce8be710290b8c431bbc97f405d15.js"></script>

    






  
  
  <div class="container">
    <footer class="site-footer">
  

  <p class="powered-by">
    
  </p>

  
  






  <p class="powered-by">
    Powered by the
    <a href="https://sourcethemes.com/academic/" target="_blank" rel="noopener">Academic theme</a> for
    <a href="https://gohugo.io" target="_blank" rel="noopener">Hugo</a>.

    
    <span class="float-right" aria-hidden="true">
      <a href="#" class="back-to-top">
        <span class="button_icon">
          <i class="fas fa-chevron-up fa-2x"></i>
        </span>
      </a>
    </span>
    
  </p>
</footer>

  </div>
  

  
<div id="modal" class="modal fade" role="dialog">
  <div class="modal-dialog">
    <div class="modal-content">
      <div class="modal-header">
        <h5 class="modal-title">Cite</h5>
        <button type="button" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body">
        <pre><code class="tex hljs"></code></pre>
      </div>
      <div class="modal-footer">
        <a class="btn btn-outline-primary my-1 js-copy-cite" href="#" target="_blank">
          <i class="fas fa-copy"></i> Copy
        </a>
        <a class="btn btn-outline-primary my-1 js-download-cite" href="#" target="_blank">
          <i class="fas fa-download"></i> Download
        </a>
        <div id="modal-error"></div>
      </div>
    </div>
  </div>
</div>

</body>
</html>
